{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cjkc06kUOGlS"
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-MkijxYQN_f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aW4sLVQlO7lr"
   },
   "outputs": [],
   "source": [
    "!pip install simpletransformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnrg7rRZQWG0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from collections import Counter\n",
    "import re\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import re\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4F1n07VtcjpG"
   },
   "outputs": [],
   "source": [
    "tokenizer_bart_large = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "model_bart_large = BartForConditionalGeneration.from_pretrained('facebook/bart-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEC7vbnaQhME"
   },
   "outputs": [],
   "source": [
    "columns = ['MRN', 'ID', 'DATE', 'TYPE', 'TEXT']\n",
    "notes_1 = pd.read_csv('/content/drive/MyDrive/RA_Medical_DATA/APC_NOTES/MRN_Clinical_Notes_File1.txt', sep='\\t', names=columns)\n",
    "notes_2 = pd.read_csv('/content/drive/MyDrive/RA_Medical_DATA/APC_NOTES/MRN_Clinical_Notes_File2.txt', sep='\\t', names=columns)\n",
    "notes_3 = pd.read_csv('/content/drive/MyDrive/RA_Medical_DATA/APC_NOTES/MRN_Clinical_Notes_File3.txt', sep='\\t', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_5uXSjcibHL"
   },
   "outputs": [],
   "source": [
    "icd_notes_updated = pd.read_csv('/content/drive/MyDrive/RA_Medical_DATA/APC_NOTES/updated-diagnosis-list.csv')\n",
    "icd_notes_updated.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uR4i1ILqjGff"
   },
   "outputs": [],
   "source": [
    "icd_notes_updated.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VN1G6qEq9CU6"
   },
   "outputs": [],
   "source": [
    "icd_notes_updated_merged = icd_notes_updated.groupby('MRN')['problem'].agg(lambda x: ', '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82zGFie59Ji4"
   },
   "outputs": [],
   "source": [
    "icd_notes_updated_merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjKN-ZcsS1Bc"
   },
   "outputs": [],
   "source": [
    "label_classification = pd.read_excel('/content/drive/MyDrive/RA_Medical_DATA/APC_NOTES/classification.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e97i7j89gxxu"
   },
   "outputs": [],
   "source": [
    "label_classification.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iotkmdSg7F7"
   },
   "outputs": [],
   "source": [
    "print(label_classification['outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWeD6l5kX3oK"
   },
   "outputs": [],
   "source": [
    "notes = pd.concat([notes_1, notes_2, notes_3], axis=0)\n",
    "notes = notes[notes['TYPE'].isin(['H&P'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGcVE641ZimI"
   },
   "outputs": [],
   "source": [
    "def clean_input(input_text):\n",
    "    cleaned_text = re.sub(r\"&#x0A;\", \"\", input_text)\n",
    "    cleaned_text = re.sub(r\"-{3,}\", \"\", cleaned_text)\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpIloDVAaiVF"
   },
   "outputs": [],
   "source": [
    "notes['TEXT'] = notes['TEXT'].apply(clean_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9YxnTtEdnXz"
   },
   "outputs": [],
   "source": [
    "notes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSLepUzmI2Db"
   },
   "outputs": [],
   "source": [
    "notes['DATE_NEW'] = pd.to_datetime(notes['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eWFz77jT2MV"
   },
   "outputs": [],
   "source": [
    "notes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXI2MdPWT2H1"
   },
   "outputs": [],
   "source": [
    "notes['text_length'] = notes['TEXT'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOL-lmYgWBrW"
   },
   "outputs": [],
   "source": [
    "notes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1K_ZIkUT1_I"
   },
   "outputs": [],
   "source": [
    "average_length = notes['text_length'].mean()\n",
    "\n",
    "print(average_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TY6mTXmGV0AF"
   },
   "outputs": [],
   "source": [
    "Q1 = notes['text_length'].quantile(0.25)\n",
    "Q3 = notes['text_length'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Filter out rows with text lengths within the acceptable range (excluding outliers)\n",
    "filtered_notes_for_length = notes[(notes['text_length'] >= Q1 - 1.5 * IQR) & (notes['text_length'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "# Calculate the average length of text after excluding outliers\n",
    "average_length_excluding_outliers = filtered_notes_for_length['text_length'].mean()\n",
    "\n",
    "print(\"Average length of text (excluding outliers):\", average_length_excluding_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uy_FQ8cuI2A6"
   },
   "outputs": [],
   "source": [
    "notes_filtered = notes[notes['TEXT'].apply(lambda x: len(x) > 1800)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JWRf6rqMGcg"
   },
   "outputs": [],
   "source": [
    "notes_filtered = notes_filtered.sort_values(['MRN', 'DATE_NEW'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GIHXrTnqbnMz"
   },
   "outputs": [],
   "source": [
    "df_notes = notes_filtered.groupby('MRN').agg({'TEXT': lambda x: ' '.join(x.head(1))}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdeyNtGaemWK"
   },
   "outputs": [],
   "source": [
    "def generate_summary(sentences):\n",
    "    inputs = tokenizer_bart_large(sentences, return_tensors='pt')\n",
    "    print('Input shape:', inputs.input_ids.shape)\n",
    "\n",
    "  # Check if tokenization resulted in more than one chunk\n",
    "    if inputs.input_ids.shape[1] > 1024:\n",
    "      # Split the input into smaller chunks\n",
    "        chunked_input_ids = inputs.input_ids[0].split(1024)\n",
    "        chunked_attention_mask = inputs.attention_mask[0].split(1024)\n",
    "        generated_ids = []\n",
    "\n",
    "      # Generate text for each chunk\n",
    "        for i in range(len(chunked_input_ids)):\n",
    "            input_ids = chunked_input_ids[i].unsqueeze(0)\n",
    "            attention_mask = chunked_attention_mask[i].unsqueeze(0)\n",
    "\n",
    "          # Generate text for the current chunk\n",
    "            generated_ids_chunk = model_bart_large.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                num_beams=5,\n",
    "                min_length=100,\n",
    "                max_length=300\n",
    "            )\n",
    "\n",
    "            generated_ids.extend(generated_ids_chunk.tolist())\n",
    "\n",
    "      # Concatenate the generated chunks\n",
    "        generated_ids = generated_ids[0]\n",
    "    else:\n",
    "      # Generate text for the entire input\n",
    "        generated_ids = model_bart_large.generate(\n",
    "            input_ids=inputs.input_ids,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "            num_beams=5,\n",
    "            min_length=100,\n",
    "            max_length=300\n",
    "            )\n",
    "        generated_ids = generated_ids.tolist()\n",
    "        generated_ids = generated_ids[0]\n",
    "\n",
    "  # Decode the generated output\n",
    "    generated_text = tokenizer_bart_large.decode(generated_ids, skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0RG-qf4NdWQ"
   },
   "outputs": [],
   "source": [
    "df_notes['Summarised_Text'] = df_notes['TEXT'].apply(generate_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqeMQ-RN7rMd"
   },
   "outputs": [],
   "source": [
    "# concatenated_data = pd.read_csv('/content/drive/MyDrive/RA_Medical_DATA/APC_NOTES/concatenated_data.csv')\n",
    "# df_notes = concatenated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUb_gBjfd-q6"
   },
   "outputs": [],
   "source": [
    "df_notes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SP-Bk_5Hea6G"
   },
   "outputs": [],
   "source": [
    "data_classification = pd.merge(df_notes, label_classification, on='MRN', how='inner').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yi6XU80yhhQl"
   },
   "outputs": [],
   "source": [
    "def remove_na(input_text):\n",
    "    cleaned_text = input_text.replace('nan', '')\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfJdmf_PiTtu"
   },
   "outputs": [],
   "source": [
    "data_classification = pd.merge(data_classification, icd_notes_updated_merged, on='MRN', how='inner').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9spJtFPib2s"
   },
   "outputs": [],
   "source": [
    "data_classification.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2-F_j_IionV"
   },
   "outputs": [],
   "source": [
    "y_train_classification = data_classification[['outcome']]\n",
    "X_train_classification = pd.concat(['Problem: ' + data_classification['problem'] + '.Summary Report: ' + data_classification['Summarised_Text']] ,  axis=1)\n",
    "X_train_classification.columns = ['text']\n",
    "y_train_classification.columns = ['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3y3fLr9kFnI"
   },
   "outputs": [],
   "source": [
    "data_final_classification = pd.concat([X_train_classification, y_train_classification], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0D3T0eejnNu"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data_final_classification, test_size=0.25, random_state=42)\n",
    "train_data = train_data.reset_index(drop = True)\n",
    "test_data = test_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ua44CmMx9X7M"
   },
   "outputs": [],
   "source": [
    "minority_class = train_data[train_data['labels'] == 0]\n",
    "majority_class = train_data[train_data['labels'] == 1]\n",
    "\n",
    "print(len(minority_class), len(majority_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHV0zB569X4m"
   },
   "outputs": [],
   "source": [
    "oversampled_minority_class = minority_class.sample(n=287, replace=True, random_state=42)\n",
    "print(len(oversampled_minority_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DknHrgX9X0M"
   },
   "outputs": [],
   "source": [
    "balanced_df = pd.concat([majority_class, oversampled_minority_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrDmRh9QCwUR"
   },
   "outputs": [],
   "source": [
    "train_data = balanced_df\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5c4dbBrkVI1"
   },
   "outputs": [],
   "source": [
    "train_data_no_sampling, test_data_no_sampling = train_test_split(data_final_classification, test_size=0.25, random_state=42)\n",
    "train_data_no_sampling = train_data_no_sampling.reset_index(drop = True)\n",
    "test_data_no_sampling = test_data_no_sampling.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6m0C0sOHlAN7"
   },
   "outputs": [],
   "source": [
    "def calculate_values(result, model):\n",
    "\n",
    "  # Calculate Precision\n",
    "  precision = result['tp'] / (result['tp'] + result['fp'])\n",
    "\n",
    "  # Calculate Recall (Sensitivity)\n",
    "  recall = result['tp'] / (result['tp'] + result['fn'])\n",
    "\n",
    "  # Calculate F1 Score\n",
    "  f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "  # Calculate Accuracy\n",
    "  accuracy = (result['tp'] + result['tn']) / (result['tp'] + result['tn'] + result['fp'] + result['fn'])\n",
    "\n",
    "  # Calculate Specificity\n",
    "  specificity = result['tn'] / (result['tn'] + result['fp'])\n",
    "\n",
    "  # Calculate AUC-ROC\n",
    "  auc_roc = result['auroc']\n",
    "\n",
    "  # Calculate ROC\n",
    "  roc = {\n",
    "      'fpr': result['fp'] / (result['fp'] + result['tn']),\n",
    "      'tpr': recall\n",
    "  }\n",
    "\n",
    "  # Print the calculated metrics\n",
    "  print(\"Precision:\",model, \": \", precision)\n",
    "  print(\"Recall:\",model, \": \", recall)\n",
    "  print(\"F1 Score:\", model, \": \", f1)\n",
    "  print(\"Accuracy:\", model, \": \", accuracy)\n",
    "  print(\"Sensitivity:\", model, \": \", recall)\n",
    "  print(\"Specificity:\", model, \": \", specificity)\n",
    "  print(\"AUC-ROC:\", model, \": \", auc_roc)\n",
    "  print(\"ROC:\", model, \": \", roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPsoNonIC23w"
   },
   "outputs": [],
   "source": [
    "def draw_plots(predicted_probabilities, true_labels, model):\n",
    "\n",
    "  auc_score = roc_auc_score(true_labels, predicted_probabilities)\n",
    "  fpr, tpr, _ = roc_curve(true_labels, predicted_probabilities)\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(fpr, tpr, label=f\"auroc = {auc_score:.2f}\")\n",
    "  plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line representing random classification\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.title('Rceiver Operating Characteristic Curve for ' + model)\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.show()\n",
    "\n",
    "  print(\" \")\n",
    "\n",
    "  average_precision = average_precision_score(true_labels, predicted_probabilities)\n",
    "  precision, recall, _ = precision_recall_curve(true_labels, predicted_probabilities)\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(recall, precision, label=f\"auprc = {average_precision:.2f}\")\n",
    "  plt.xlabel('Recall')\n",
    "  plt.ylabel('Precision')\n",
    "  plt.title('Precision-Recall Curve for ' + model)\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgRX7vGkq6Vb"
   },
   "outputs": [],
   "source": [
    "def calculate_f1(result):\n",
    "  precision = result['tp'] / (result['tp'] + result['fp'])\n",
    "  recall = result['tp'] / (result['tp'] + result['fn'])\n",
    "\n",
    "  f1 = (2 * precision * recall)/(precision + recall)\n",
    "  return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L44LalrK_dw9"
   },
   "source": [
    "### BERT Based Uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fg2UeH5wkXJi"
   },
   "outputs": [],
   "source": [
    "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir = True, max_seq_length=512)\n",
    "\n",
    "model_bert_base_uncased = ClassificationModel(\n",
    "    \"bert\", \"bert-base-uncased\", args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hs47k2PSoyCt"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "  model_bert_base_uncased.train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIHQa7WJo3Lo"
   },
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model_bert_base_uncased.eval_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUiLDS8fo33V"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10sunAbsg3xy"
   },
   "outputs": [],
   "source": [
    "calculate_values(result, 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDp57MpWrJE7"
   },
   "outputs": [],
   "source": [
    "predicted_probabilities_bert = model_outputs[:, 1]\n",
    "true_labels_bert = np.array(test_data['labels'].tolist())\n",
    "draw_plots(predicted_probabilities_bert, true_labels_bert, 'bert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSg2LmgY_zxC"
   },
   "source": [
    "### roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GYzSC3I_9zP"
   },
   "outputs": [],
   "source": [
    "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir = True, max_seq_length=512)\n",
    "\n",
    "model_roberta = ClassificationModel(\n",
    "    \"roberta\", \"roberta-base\", args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thPTSunNYMIf"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "  model_roberta.train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Onq40qFYOBZ"
   },
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model_roberta.eval_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsjuVXqCY2E4"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UQ3cou6Y1_8"
   },
   "outputs": [],
   "source": [
    "calculate_values(result, 'roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "232akXQpDFq5"
   },
   "outputs": [],
   "source": [
    "predicted_probabilities_roberta = model_outputs[:, 1]\n",
    "true_labels_roberta = np.array(test_data['labels'].tolist())\n",
    "draw_plots(predicted_probabilities_roberta, true_labels_roberta, 'roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zUOBbjlAdDg"
   },
   "source": [
    "### emilyalsentzer/Bio_ClinicalBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBvDrZqNA4bh"
   },
   "outputs": [],
   "source": [
    "# model_args = ClassificationArgs(num_train_epochs=5, overwrite_output_dir = True, sliding_window=True)\n",
    "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir = True, max_seq_length=512)\n",
    "\n",
    "model_Bio_ClinicalBERT= ClassificationModel(\n",
    "    \"bert\", \"emilyalsentzer/Bio_ClinicalBERT\", args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7If_9e0HdVRn"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "  model_Bio_ClinicalBERT.train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UROejO99dVPR"
   },
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model_Bio_ClinicalBERT.eval_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hMCdUN5flf1"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLcN5hPnfldt"
   },
   "outputs": [],
   "source": [
    "calculate_values(result, 'Bio-Bertt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDexLFVDD3Xo"
   },
   "outputs": [],
   "source": [
    "predicted_probabilities_biobert= model_outputs[:, 1]\n",
    "true_labels_biobert = np.array(test_data['labels'].tolist())\n",
    "draw_plots(predicted_probabilities_biobert, true_labels_biobert, 'Bio_ClinicalBERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzu7cdtiBUXq"
   },
   "source": [
    "### microsoft/BiomedNLP-PubMedBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqjGQq9MBY8V"
   },
   "outputs": [],
   "source": [
    "# model_args = ClassificationArgs(num_train_epochs=5, overwrite_output_dir = True, sliding_window=True)\n",
    "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir = True, max_seq_length=512)\n",
    "\n",
    "model_microsoft_bio_pubmed =  ClassificationModel(\n",
    "    \"bert\", \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\", args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3_v_auNi1uG"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "  model_microsoft_bio_pubmed.train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ir_dYuVni0_t"
   },
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model_microsoft_bio_pubmed.eval_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTCPSd47BieX"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g19Dh8TpBief"
   },
   "outputs": [],
   "source": [
    "calculate_values(result, 'PubMedBert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1O_KOl2eCW38"
   },
   "outputs": [],
   "source": [
    "predicted_probabilities_pubmed = model_outputs[:, 1]\n",
    "true_labels_pubmed = np.array(test_data['labels'].tolist())\n",
    "draw_plots(predicted_probabilities_pubmed, true_labels_pubmed, 'PubMedBERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYHU9maKEIhC"
   },
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Vwr6Xh_EI4R"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIADfD4mELU9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, average_precision_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_roc_curve(predicted_probabilities, true_labels, model_name):\n",
    "    auc_score = roc_auc_score(true_labels, predicted_probabilities)\n",
    "    fpr, tpr, _ = roc_curve(true_labels, predicted_probabilities)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {auc_score:.2f})\")\n",
    "\n",
    "def draw_precision_recall_curve(predicted_probabilities, true_labels, model_name):\n",
    "    average_precision = average_precision_score(true_labels, predicted_probabilities)\n",
    "    precision, recall, _ = precision_recall_curve(true_labels, predicted_probabilities)\n",
    "\n",
    "    plt.plot(recall, precision, label=f\"{model_name} (AP = {average_precision:.2f})\")\n",
    "\n",
    "def draw_plots_multiple(predicted_probabilities_list, true_labels_list, model_names):\n",
    "    plt.figure()\n",
    "\n",
    "    for i, predicted_probabilities in enumerate(predicted_probabilities_list):\n",
    "        model_name = model_names[i]\n",
    "        true_labels = true_labels_list[i]\n",
    "        draw_roc_curve(predicted_probabilities, true_labels, model_name)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "\n",
    "    print(\" \")\n",
    "\n",
    "    for i, predicted_probabilities in enumerate(predicted_probabilities_list):\n",
    "        model_name = model_names[i]\n",
    "        true_labels = true_labels_list[i]\n",
    "        draw_precision_recall_curve(predicted_probabilities, true_labels, model_name)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvkFahvJEPKB"
   },
   "outputs": [],
   "source": [
    "# predicted_probabilities_list = [predicted_probabilities_roberta, predicted_probabilities_bert, predicted_probabilities_biobert, predicted_probabilities_pubmed, predicted_probabilities_longformer]\n",
    "# true_labels_list = [true_labels_roberta, true_labels_bert, true_labels_biobert, true_labels_pubmed, true_labels_longformer]\n",
    "# model_names = [\"Roberta\", \"Bert-base-uncase\", \"Bio_ClinicalBERT\", \"PubMedBERT\", \"Longformer\"]\n",
    "\n",
    "# draw_plots_multiple(predicted_probabilities_list, true_labels_list, model_names)\n",
    "\n",
    "predicted_probabilities_list = [predicted_probabilities_roberta, predicted_probabilities_bert, predicted_probabilities_biobert, predicted_probabilities_pubmed]\n",
    "true_labels_list = [true_labels_roberta, true_labels_bert, true_labels_biobert, true_labels_pubmed]\n",
    "model_names = [\"Roberta\", \"Bert-base-uncase\", \"Bio_ClinicalBERT\", \"PubMedBERT\"]\n",
    "\n",
    "draw_plots_multiple(predicted_probabilities_list, true_labels_list, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUqhdEHXMHjS"
   },
   "outputs": [],
   "source": [
    "def write_list_to_txt(lst, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for item in lst:\n",
    "            file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMOK6BzJMHu8"
   },
   "outputs": [],
   "source": [
    "write_list_to_txt(predicted_probabilities_list, \"predicted_probabilities_list\")\n",
    "write_list_to_txt(true_labels_list, \"true_labels_list\")\n",
    "write_list_to_txt(model_names, \"model_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-YPUHKDMJfd"
   },
   "outputs": [],
   "source": [
    "def read_txt_to_list(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        data_list = [line.strip() for line in lines]\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65BvoZ7JMMU_"
   },
   "outputs": [],
   "source": [
    "predicted_probabilities_list_1 = read_txt_to_list(\"predicted_probabilities_list\")\n",
    "true_labels_list_1 = read_txt_to_list(\"true_labels_list\")\n",
    "model_names_1 = read_txt_to_list(\"model_names\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
